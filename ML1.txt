ðŸš— ML Assignment 1: Uber Fare Price Prediction
ðŸŽ¯ Objective

Predict Uber fare price using Linear Regression and Random Forest Regression after data preprocessing, outlier handling, and correlation checking.

ðŸ§  Steps to Perform (Copy this code into Jupyter Notebook)
Step 1: Import Libraries
# Step 1: Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error

Step 2: Load Dataset

(Download from: https://www.kaggle.com/datasets/yasserh/uber-fares-dataset
)

# Step 2: Load dataset
df = pd.read_csv("uber.csv")
df.head()

Step 3: Data Preprocessing
# Check for missing values
print(df.isnull().sum())

# Drop rows with missing fare_amount or coordinates
df = df.dropna()

# Keep only reasonable fare values
df = df[(df['fare_amount'] > 0) & (df['fare_amount'] < 100)]
df = df[(df['pickup_longitude'] != 0) & (df['pickup_latitude'] != 0)]

Step 4: Feature Engineering (Haversine Distance)

Haversine formula helps find distance between pickup & drop locations.

# Function to calculate distance
def haversine(lat1, lon1, lat2, lon2):
    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])
    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    r = 6371  # Radius of earth in kilometers
    return c * r

# Apply distance function
df['distance_km'] = haversine(df['pickup_latitude'], df['pickup_longitude'],
                              df['dropoff_latitude'], df['dropoff_longitude'])

Step 5: Handle Outliers
# Visualize outliers
sns.boxplot(df['fare_amount'])
plt.show()

# Remove unrealistic distance or fare
df = df[(df['distance_km'] < 50) & (df['distance_km'] > 0)]

Step 6: Check Correlation
# Correlation Heatmap
plt.figure(figsize=(5,3))
sns.heatmap(df[['fare_amount','distance_km']].corr(), annot=True, cmap='coolwarm')
plt.show()

Step 7: Split Data
X = df[['distance_km']]
y = df['fare_amount']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Step 8: Train Models
Linear Regression
lr = LinearRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

Random Forest Regression
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

Step 9: Evaluate Models
def evaluate_model(y_true, y_pred, model_name):
    r2 = r2_score(y_true, y_pred)
    rmse = np.sqrt(mean_squared_error(y_true, y_pred))
    print(f"{model_name} -> R2 Score: {r2:.3f}, RMSE: {rmse:.3f}")

evaluate_model(y_test, y_pred_lr, "Linear Regression")
evaluate_model(y_test, y_pred_rf, "Random Forest Regression")

Step 10: Visual Comparison
plt.scatter(y_test, y_pred_lr, color='blue', label='Linear Regression', alpha=0.5)
plt.scatter(y_test, y_pred_rf, color='red', label='Random Forest', alpha=0.5)
plt.xlabel('Actual Fare')
plt.ylabel('Predicted Fare')
plt.legend()
plt.title('Actual vs Predicted Uber Fares')
plt.show()

ðŸ§¾ Output Youâ€™ll Get

Clean dataset

Correlation heatmap

Box plot for outliers

RÂ² and RMSE for both models

Scatter plot showing prediction comparison

âš™ï¸ Example Result
Linear Regression -> R2 Score: 0.85, RMSE: 2.34
Random Forest Regression -> R2 Score: 0.93, RMSE: 1.45


(These numbers vary depending on your cleaned dataset.)

Would you like me to create a ready-to-run .ipynb Jupyter notebook file for this so you can directly open it and execute it step-by-step?