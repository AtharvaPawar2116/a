‚úÖ Step 1: Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage, fcluster

‚úÖ Step 2: Load Dataset
# Load dataset
df = pd.read_csv("sales_data_sample.csv", encoding='unicode_escape')
df.head()

‚úÖ Step 3: Data Preprocessing
# Check missing values
print(df.isnull().sum())

# Drop unnecessary columns (like text IDs or dates)
df_clean = df.select_dtypes(include=[np.number])   # keep only numeric columns

# Handle missing numeric values if any
df_clean = df_clean.dropna()

# Scale data for clustering
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df_clean)

‚úÖ Step 4: Elbow Method ‚Äì Find Optimal Number of Clusters
wcss = []  # within-cluster sum of squares

for i in range(1, 11):
    kmeans = KMeans(n_clusters=i, random_state=42)
    kmeans.fit(scaled_data)
    wcss.append(kmeans.inertia_)

# Plot Elbow Curve
plt.figure(figsize=(8,5))
plt.plot(range(1,11), wcss, marker='o', linestyle='--')
plt.title('Elbow Method for Optimal k')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('WCSS')
plt.show()


üîπ Interpretation:
Look for the ‚Äúelbow‚Äù (where the curve starts to flatten).
That value of k is your optimal cluster count.

‚úÖ Step 5: Apply K-Means Clustering
# Assume elbow shows k=3 (you can change based on your plot)
kmeans = KMeans(n_clusters=3, random_state=42)
df_clean['Cluster'] = kmeans.fit_predict(scaled_data)

# Visualize clusters using first two principal components
plt.figure(figsize=(8,5))
plt.scatter(scaled_data[:,0], scaled_data[:,1], c=df_clean['Cluster'], cmap='viridis')
plt.title("K-Means Clustering Visualization")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()

‚úÖ Step 6: Analyze Cluster Results
# Check cluster-wise mean of features
cluster_summary = df_clean.groupby('Cluster').mean()
print(cluster_summary)
